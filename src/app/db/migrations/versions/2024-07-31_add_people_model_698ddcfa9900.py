# type: ignore
"""Add people model

Revision ID: 698ddcfa9900
Revises: a05c476c0ae9
Create Date: 2024-07-31 09:48:08.467309+00:00

"""
from __future__ import annotations

import warnings
from typing import TYPE_CHECKING

import sqlalchemy as sa
from alembic import op
from advanced_alchemy.types import EncryptedString, EncryptedText, GUID, ORA_JSONB, DateTimeUTC
from sqlalchemy import Text  # noqa: F401
from sqlalchemy.dialects import postgresql
from app.db.models.custom_types import LocationType, WorkExperienceType, SocialActivityType

if TYPE_CHECKING:
    from collections.abc import Sequence

__all__ = ["downgrade", "upgrade", "schema_upgrades", "schema_downgrades", "data_upgrades", "data_downgrades"]

sa.GUID = GUID
sa.DateTimeUTC = DateTimeUTC
sa.ORA_JSONB = ORA_JSONB
sa.EncryptedString = EncryptedString
sa.EncryptedText = EncryptedText

# revision identifiers, used by Alembic.
revision = "698ddcfa9900"
down_revision = "a05c476c0ae9"
branch_labels = None
depends_on = None


def upgrade() -> None:
    with warnings.catch_warnings():
        warnings.filterwarnings("ignore", category=UserWarning)
        with op.get_context().autocommit_block():
            schema_upgrades()
            data_upgrades()


def downgrade() -> None:
    with warnings.catch_warnings():
        warnings.filterwarnings("ignore", category=UserWarning)
        with op.get_context().autocommit_block():
            data_downgrades()
            schema_downgrades()


def schema_upgrades() -> None:
    """schema upgrade migrations go here."""
    # ### commands auto generated by Alembic - please adjust! ###
    op.create_table(
        "person",
        sa.Column("id", sa.GUID(length=16), nullable=False),
        sa.Column("first_name", sa.String(), nullable=True),
        sa.Column("last_name", sa.String(), nullable=True),
        sa.Column("full_name", sa.String(), nullable=True),
        sa.Column("headline", sa.String(length=500), nullable=True),
        sa.Column("summary", sa.String(length=2000), nullable=True),
        sa.Column("occupation", sa.String(), nullable=True),
        sa.Column("industry", sa.String(), nullable=True),
        sa.Column("profile_pic_url", sa.String(length=2083), nullable=True),
        sa.Column("url", sa.String(length=2083), nullable=True),
        sa.Column("linkedin_profile_url", sa.String(length=2083), nullable=True),
        sa.Column("twitter_profile_url", sa.String(length=2083), nullable=True),
        sa.Column("github_profile_url", sa.String(length=2083), nullable=True),
        sa.Column("location", LocationType(), nullable=True),
        sa.Column("personal_emails", postgresql.JSONB(astext_type=sa.Text()), nullable=True),
        sa.Column("work_emails", postgresql.JSONB(astext_type=sa.Text()), nullable=True),
        sa.Column("personal_numbers", postgresql.JSONB(astext_type=sa.Text()), nullable=True),
        sa.Column("birth_date", sa.Date(), nullable=True),
        sa.Column("gender", sa.String(), nullable=True),
        sa.Column("languages", postgresql.JSONB(astext_type=sa.Text()), nullable=True),
        sa.Column("work_experiences", WorkExperienceType(), nullable=True),
        sa.Column("social_activities", SocialActivityType(), nullable=True),
        sa.Column("slug", sa.String(length=100), nullable=False),
        sa.Column("sa_orm_sentinel", sa.Integer(), nullable=True),
        sa.Column("created_at", sa.DateTimeUTC(timezone=True), nullable=False),
        sa.Column("updated_at", sa.DateTimeUTC(timezone=True), nullable=False),
        sa.PrimaryKeyConstraint("id", name=op.f("pk_person")),
        sa.UniqueConstraint("slug", name="uq_person_slug"),
    )
    with op.batch_alter_table("person", schema=None) as batch_op:
        batch_op.create_index(batch_op.f("ix_person_industry"), ["industry"], unique=False)
        batch_op.create_index("ix_person_slug_unique", ["slug"], unique=True)

    # ### end Alembic commands ###


def schema_downgrades() -> None:
    """schema downgrade migrations go here."""
    # ### commands auto generated by Alembic - please adjust! ###
    with op.batch_alter_table("person", schema=None) as batch_op:
        batch_op.drop_index("ix_person_slug_unique")
        batch_op.drop_index(batch_op.f("ix_person_industry"))

    op.drop_table("person")
    # ### end Alembic commands ###


def data_upgrades() -> None:
    """Add any optional data upgrade migrations here!"""


def data_downgrades() -> None:
    """Add any optional data downgrade migrations here!"""
